{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c8329a",
   "metadata": {},
   "source": [
    "### Data Injection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34334236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Syed', 'data_created': '2025-09-01'}, page_content='This is the main text content')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content\",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"Syed\",\n",
    "        \"data_created\": \"2025-09-01\",\n",
    "    },\n",
    ")\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93c62a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/textfiles/python.txt'}, page_content='Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. It was created by Guido van Rossum and first released in 1991.\\nHere‚Äôs a breakdown of what makes Python special:\\nüß† Key Features\\nEasy to Read and Write ‚Äì Python‚Äôs syntax is close to natural English, which makes it beginner-friendly.\\nInterpreted ‚Äì You don‚Äôt need to compile Python code; it runs line by line.\\nDynamically Typed ‚Äì You don‚Äôt need to declare variable types (e.g., x = 10 just works).\\nObject-Oriented and Functional ‚Äì Supports multiple programming paradigms.\\nExtensive Libraries ‚Äì Comes with a large standard library and third-party modules (e.g., NumPy, Pandas, TensorFlow).\\nCross-Platform ‚Äì Runs on Windows, macOS, Linux, and more.\\n‚öôÔ∏è Common Uses\\nWeb development ‚Äì with frameworks like Django and Flask\\nData science & machine learning ‚Äì using NumPy, Pandas, scikit-learn, TensorFlow, PyTorch\\nAutomation & scripting ‚Äì to automate repetitive tasks\\nSoftware testing ‚Äì for unit testing and QA\\nGame development ‚Äì via Pygame and other libraries\\nCybersecurity & networking ‚Äì for scripting and penetration testing')]\n"
     ]
    }
   ],
   "source": [
    "##Text Loader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/textfiles/python.txt\", \"utf-8\")\n",
    "\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81f8b336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/textfiles/machinelearning.txt'}, page_content='Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables computers to learn from data and improve their performance over time ‚Äî without being explicitly programmed to perform specific tasks.\\nüß† In Simple Terms\\nInstead of writing rules for every possible situation, we feed data to an algorithm, and the algorithm finds patterns and makes decisions or predictions on its own.\\n‚öôÔ∏è How It Works\\nCollect Data ‚Üí Example: pictures of cats and dogs.\\nTrain a Model ‚Üí The algorithm learns patterns (e.g., shapes, colors, features) from the data.\\nTest the Model ‚Üí See how well it performs on new, unseen data.\\nMake Predictions ‚Üí The model can now predict, for example, whether a new image is a cat or a dog.\\nüß© Types of Machine Learning\\nSupervised Learning\\nThe model learns from labeled data (input and correct output).\\nüìò Example: Predicting house prices from features like size and location.\\nUnsupervised Learning\\nThe model finds hidden patterns in unlabeled data.\\nüìó Example: Grouping customers by buying habits (clustering).\\nReinforcement Learning\\nThe model learns by trial and error, getting rewards or penalties for actions.\\nüìô Example: Training a robot to walk or an AI to play chess.\\nüí° Real-World Applications\\nVoice Assistants (Siri, Alexa)\\nRecommendation Systems (Netflix, YouTube, Amazon)\\nFraud Detection (banking and credit cards)\\nSelf-Driving Cars\\nMedical Diagnosis'),\n",
       " Document(metadata={'source': '../data/textfiles/python.txt'}, page_content='Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. It was created by Guido van Rossum and first released in 1991.\\nHere‚Äôs a breakdown of what makes Python special:\\nüß† Key Features\\nEasy to Read and Write ‚Äì Python‚Äôs syntax is close to natural English, which makes it beginner-friendly.\\nInterpreted ‚Äì You don‚Äôt need to compile Python code; it runs line by line.\\nDynamically Typed ‚Äì You don‚Äôt need to declare variable types (e.g., x = 10 just works).\\nObject-Oriented and Functional ‚Äì Supports multiple programming paradigms.\\nExtensive Libraries ‚Äì Comes with a large standard library and third-party modules (e.g., NumPy, Pandas, TensorFlow).\\nCross-Platform ‚Äì Runs on Windows, macOS, Linux, and more.\\n‚öôÔ∏è Common Uses\\nWeb development ‚Äì with frameworks like Django and Flask\\nData science & machine learning ‚Äì using NumPy, Pandas, scikit-learn, TensorFlow, PyTorch\\nAutomation & scripting ‚Äì to automate repetitive tasks\\nSoftware testing ‚Äì for unit testing and QA\\nGame development ‚Äì via Pygame and other libraries\\nCybersecurity & networking ‚Äì for scripting and penetration testing')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Directory Loader\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/textfiles\",\n",
    "    glob=\"**/*.txt\",  # pattern to match filename\n",
    "    loader_cls=TextLoader,  # loader class to use\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=False,\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b334ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\",  # pattern to match filename\n",
    "    loader_cls=PyMuPDFLoader,  # loader class to use\n",
    "    show_progress=False,\n",
    ")\n",
    "\n",
    "pdf_documents = dir_loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c561fe",
   "metadata": {},
   "source": [
    "### RAG Pipelines - Data Injection to VectorDB Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "34e3fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aac88927",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read all pdfs inside directory\n",
    "\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # find all pdf recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\n Processing : {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Add metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source_file\"] = pdf_file.name\n",
    "                doc.metadata[\"file_type\"] = \"pdf\"\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"‚úÖ Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error {e}\")\n",
    "\n",
    "    print(f\"\\n Total documents loaded:{len(all_documents)}\")\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7b58d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 PDF files to process\n",
      "\n",
      " Processing : repealedfileopen.pdf\n",
      "‚úÖ Loaded 119 pages\n",
      "\n",
      " Total documents loaded:119\n"
     ]
    }
   ],
   "source": [
    "all_pdf_documents = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30bd883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Text splitting into chunks\n",
    "\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # show one chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content : {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata : {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b334bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 119 documents into 643 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content : 1 \n",
      " \n",
      "THE INDIAN PENAL CODE \n",
      "___________ \n",
      "ARRANGEMENT OF SECTIONS \n",
      "__________ \n",
      "CHAPTER I \n",
      "INTRODUCTION \n",
      "PREAMBLE \n",
      "SECTIONS \n",
      "1. Title and extent of operation of the Code.  \n",
      "2. Punishment of offences com...\n",
      "Metadata : {'producer': 'Online2PDF.com', 'creator': 'Online2PDF.com', 'creationdate': '2023-06-28T10:58:56+02:00', 'source': '../data/pdf/repealedfileopen.pdf', 'total_pages': 119, 'page': 0, 'page_label': '1', 'source_file': 'repealedfileopen.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunk = split_documents(all_pdf_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426d5fb",
   "metadata": {},
   "source": [
    "### Embedding and Vector Store DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b85a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d601f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model Loaded Successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1619fe510>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using sentence transformer\"\"\"\n",
    "\n",
    "    def __init__(self,model_name:str ='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "\n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load sentence transformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model Loaded Successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name} : {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self,texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        Args:\n",
    "            text : List of text strings to embed\n",
    "        \n",
    "        Returns:\n",
    "            numpay array of embedding with length and embedded dimension\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded. \")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts..\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc583ca",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af8c978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection : pdf_documents\n",
      "Existing document in collection : 1286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1680e5010>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a chromaDb vector store\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        collection_name: str = \"pdf_documents\",\n",
    "        persist_directory: str = \"../data/vector_store\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the chromaDB collection,\n",
    "            persist_directory: Directory to persist vector store\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize chromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"},\n",
    "            )\n",
    "\n",
    "            print(f\"Vector store initialized. Collection : {self.collection_name}\")\n",
    "            print(f\"Existing document in collection : {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents: List of Langchain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match numnber of documents\")\n",
    "\n",
    "        print(f\"Adding {len(documents)} documents to vector store.....\")\n",
    "\n",
    "        # prepare data for chromadb\n",
    "\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "            #Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #Preparing metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            #Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            #embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Eroor adding documents to chromaDB: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "vector_store = VectorStore()\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849cf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8454168",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc.page_content for doc in chunk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f0b49ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 643 texts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:04<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (643, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Generate embeddings\n",
    "\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6d6614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 643 documents to vector store.....\n",
      "Successfully added 643 documents to vector store\n",
      "Total documents in collection: 1929\n"
     ]
    }
   ],
   "source": [
    "#store in the vector database\n",
    "vector_store.add_documents(chunk,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da3261",
   "metadata": {},
   "source": [
    "## Retriver Pipeline from VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d12da335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query based retrievel from the vector store\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "\n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings,\n",
    "            embedding_manager: Manager for generating quer embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k:int = 5, score_threshold:float = 0.0) -> List[Dict[str,Any]]:\n",
    "        \"\"\" \n",
    "        Retrieve relevant documents for a query\n",
    "\n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "        \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata    \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "\n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        #search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i,(doc_id,document,metadata,distance) in enumerate(zip(ids,documents,metadatas,distances)):\n",
    "                    #Convert distance to similarity\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata':metadata,\n",
    "                            'similarity_score':similarity_score,\n",
    "                            'distance':distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else: \n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrievel: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever = RAGRetriever(vector_store,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c384a0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x1619fd940>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0aff6fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is punishment for theft?'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_cabfd986_503',\n",
       "  'content': \"a term which may extend to seven years, and shall also be liable to fine.  \\n382. Theft after preparation made for causing death, hurt or restraint in order to the \\ncommitting of the theft .‚ÄîWhoever commits theft, having made preparation for causing death, or hurt, \\nor restraint, or fear of death, or of hurt, or of restraint, to any pe rson, in order to the committing of such \\ntheft, or in order to the effecting of his escape after the committing of such theft, or in order to the \\nretaining of property taken by such theft, shall be punished with rigorous impri sonment for a term which \\nmay extend to ten years, and shall also be liable to fine. \\n  Illustrations \\n(a) A commits theft on property in Z's possession; and while committin g this theft, he has a loaded pistol under his garment \\nhaving provided this pistol for the purpose of hurting Z in case Z sh ould resist. A has committed the offence defined in this \\nsection.\",\n",
       "  'metadata': {'producer': 'Online2PDF.com',\n",
       "   'doc_index': 503,\n",
       "   'source_file': 'repealedfileopen.pdf',\n",
       "   'content_length': 932,\n",
       "   'total_pages': 119,\n",
       "   'creationdate': '2023-06-28T10:58:56+02:00',\n",
       "   'page': 95,\n",
       "   'file_type': 'pdf',\n",
       "   'creator': 'Online2PDF.com',\n",
       "   'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page_label': '96'},\n",
       "  'similarity_score': 0.4853508472442627,\n",
       "  'distance': 0.5146491527557373,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_810bc8f8_503',\n",
       "  'content': \"a term which may extend to seven years, and shall also be liable to fine.  \\n382. Theft after preparation made for causing death, hurt or restraint in order to the \\ncommitting of the theft .‚ÄîWhoever commits theft, having made preparation for causing death, or hurt, \\nor restraint, or fear of death, or of hurt, or of restraint, to any pe rson, in order to the committing of such \\ntheft, or in order to the effecting of his escape after the committing of such theft, or in order to the \\nretaining of property taken by such theft, shall be punished with rigorous impri sonment for a term which \\nmay extend to ten years, and shall also be liable to fine. \\n  Illustrations \\n(a) A commits theft on property in Z's possession; and while committin g this theft, he has a loaded pistol under his garment \\nhaving provided this pistol for the purpose of hurting Z in case Z sh ould resist. A has committed the offence defined in this \\nsection.\",\n",
       "  'metadata': {'page_label': '96',\n",
       "   'creationdate': '2023-06-28T10:58:56+02:00',\n",
       "   'producer': 'Online2PDF.com',\n",
       "   'source_file': 'repealedfileopen.pdf',\n",
       "   'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'creator': 'Online2PDF.com',\n",
       "   'total_pages': 119,\n",
       "   'content_length': 932,\n",
       "   'doc_index': 503,\n",
       "   'page': 95},\n",
       "  'similarity_score': 0.4853508472442627,\n",
       "  'distance': 0.5146491527557373,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_48c24a13_503',\n",
       "  'content': \"a term which may extend to seven years, and shall also be liable to fine.  \\n382. Theft after preparation made for causing death, hurt or restraint in order to the \\ncommitting of the theft .‚ÄîWhoever commits theft, having made preparation for causing death, or hurt, \\nor restraint, or fear of death, or of hurt, or of restraint, to any pe rson, in order to the committing of such \\ntheft, or in order to the effecting of his escape after the committing of such theft, or in order to the \\nretaining of property taken by such theft, shall be punished with rigorous impri sonment for a term which \\nmay extend to ten years, and shall also be liable to fine. \\n  Illustrations \\n(a) A commits theft on property in Z's possession; and while committin g this theft, he has a loaded pistol under his garment \\nhaving provided this pistol for the purpose of hurting Z in case Z sh ould resist. A has committed the offence defined in this \\nsection.\",\n",
       "  'metadata': {'total_pages': 119,\n",
       "   'creationdate': '2023-06-28T10:58:56+02:00',\n",
       "   'source_file': 'repealedfileopen.pdf',\n",
       "   'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'content_length': 932,\n",
       "   'producer': 'Online2PDF.com',\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 503,\n",
       "   'creator': 'Online2PDF.com',\n",
       "   'page': 95,\n",
       "   'page_label': '96'},\n",
       "  'similarity_score': 0.4853508472442627,\n",
       "  'distance': 0.5146491527557373,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_ebc20f05_511',\n",
       "  'content': 'punished with imprisonment of either description for a term which may extend to ten years, and shall also \\nbe liable to fine; and, if the offence be punishable under section 377 of this Code, m ay be punished with \\n1[imprisonment for life]. \\nOf Robbery and dacoity \\n390. Robbery.‚ÄîIn all robbery there is either theft or extortion. \\n                                                           \\n1. Subs. by Act 26 of 1955, s. 117 and the Sch., for ‚Äútransportation for life‚Äù (w.e.f. 1-1-1956).',\n",
       "  'metadata': {'creator': 'Online2PDF.com',\n",
       "   'creationdate': '2023-06-28T10:58:56+02:00',\n",
       "   'total_pages': 119,\n",
       "   'file_type': 'pdf',\n",
       "   'content_length': 489,\n",
       "   'source_file': 'repealedfileopen.pdf',\n",
       "   'producer': 'Online2PDF.com',\n",
       "   'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page': 96,\n",
       "   'doc_index': 511,\n",
       "   'page_label': '97'},\n",
       "  'similarity_score': 0.3224217891693115,\n",
       "  'distance': 0.6775782108306885,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_b46f9199_511',\n",
       "  'content': 'punished with imprisonment of either description for a term which may extend to ten years, and shall also \\nbe liable to fine; and, if the offence be punishable under section 377 of this Code, m ay be punished with \\n1[imprisonment for life]. \\nOf Robbery and dacoity \\n390. Robbery.‚ÄîIn all robbery there is either theft or extortion. \\n                                                           \\n1. Subs. by Act 26 of 1955, s. 117 and the Sch., for ‚Äútransportation for life‚Äù (w.e.f. 1-1-1956).',\n",
       "  'metadata': {'page_label': '97',\n",
       "   'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'total_pages': 119,\n",
       "   'creator': 'Online2PDF.com',\n",
       "   'creationdate': '2023-06-28T10:58:56+02:00',\n",
       "   'source_file': 'repealedfileopen.pdf',\n",
       "   'page': 96,\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 511,\n",
       "   'content_length': 489,\n",
       "   'producer': 'Online2PDF.com'},\n",
       "  'similarity_score': 0.3224217891693115,\n",
       "  'distance': 0.6775782108306885,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is punishment for theft?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148fd44",
   "metadata": {},
   "source": [
    "## Vectordb context integration with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "179d3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simple RAG Pipeline with gemini\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_KEY = os.getenv('GEMINI_API')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "188e585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",  \n",
    "    api_key=GEMINI_KEY\n",
    ")\n",
    "\n",
    "def rag_simple(query,retriver,llm,top_k=3):\n",
    "    ##Retriever the context\n",
    "    results = retriver.retrieve(query,top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content']for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevent context found to answer the question\"\n",
    "    \n",
    "    ##Generate anser using gemini\n",
    "    prompt = f\"\"\"\n",
    "    Use the following context to answer question concisely\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\n",
    "    \"\"\"\n",
    "        \n",
    "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b78997f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Murder offences?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "The provided context does not define or describe murder offences. It discusses culpable homicide and gives an example where an act leading to death was *not* considered culpable homicide due to lack of intent or knowledge.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"Murder offences?\",rag_retriever,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b2e8d",
   "metadata": {},
   "source": [
    "## Enhanced RAG Pipeline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3b280eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_advanced(query,retriver,llm,top_k=5,min_score=0.2,return_context = False):\n",
    "    \"\"\" \n",
    "    RAG Pipeline with extra features:\n",
    "        returns answer,sources,confidence score and optionally full context\n",
    "    \"\"\"\n",
    "\n",
    "    results = retriver.retrieve(query,top_k=top_k,score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer':'No relevant context found','sources':[],'confidence':0.0,'context':''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "\n",
    "    context = \"\\n\\n\".join([doc['content']for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source','unknown'),\n",
    "        'page': doc['metadata'].get('page','unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:120]+\".....\"\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "\n",
    "    # Generate answer\n",
    "\n",
    "    prompt =f\"\"\" \n",
    "        Use the following context to answer question concisely\n",
    "        context:{context}\n",
    "        question:{query}\n",
    "        answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "\n",
    "    output = {\n",
    "        'answer' :  response.content,\n",
    "        'sources' : sources,\n",
    "        'confidence' : confidence\n",
    "    }\n",
    "\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "071f9dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Punishment for sexual harrasment'\n",
      "Top K: 5, Score threshold: 0.2\n",
      "Generating embeddings for 1 texts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'For sexual harassment involving a demand or request for sexual favours, or showing pornography against the will of a woman, the punishment is rigorous imprisonment for a term which may extend to three years, or with fine, or with both.\\n\\nFor sexual harassment involving making sexually coloured remarks, the punishment is imprisonment of either description for a term which may extend to one year, or with fine, or with both.',\n",
       " 'sources': [{'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page': 83,\n",
       "   'score': 0.3714944124221802,\n",
       "   'preview': '84 \\n \\n(ii) a demand or request for sexual favours; or \\n(iii) showing pornography against the will of a woman; or \\n(iv) m.....'},\n",
       "  {'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page': 83,\n",
       "   'score': 0.3714944124221802,\n",
       "   'preview': '84 \\n \\n(ii) a demand or request for sexual favours; or \\n(iii) showing pornography against the will of a woman; or \\n(iv) m.....'},\n",
       "  {'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page': 83,\n",
       "   'score': 0.3714944124221802,\n",
       "   'preview': '84 \\n \\n(ii) a demand or request for sexual favours; or \\n(iii) showing pornography against the will of a woman; or \\n(iv) m.....'},\n",
       "  {'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page': 83,\n",
       "   'score': 0.3153412342071533,\n",
       "   'preview': 'be naked, shall be punished with imprisonment of either description for a term w hich shall not be less \\nthan three year.....'},\n",
       "  {'source': '../data/pdf/repealedfileopen.pdf',\n",
       "   'page': 83,\n",
       "   'score': 0.3153412342071533,\n",
       "   'preview': 'be naked, shall be punished with imprisonment of either description for a term w hich shall not be less \\nthan three year.....'}],\n",
       " 'confidence': 0.3714944124221802}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rag_advanced(\"Punishment for sexual harrasment\",retriver=rag_retriever,llm=llm)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "77c6e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced pipeline with steaming,History,citations,summarization...\n",
    "\n",
    "from typing import Dict, Any\n",
    "import time\n",
    "\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # To store query history\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        question: str,\n",
    "        top_k: int = 5,\n",
    "        min_score: float = 0.2,\n",
    "        stream: bool = False,\n",
    "        summarize: bool = False,\n",
    "    ) -> Dict[str, Any]:\n",
    "        # retrieve relevent documents\n",
    "        results = self.retriever.retrieve(\n",
    "            question, top_k=top_k, score_threshold=min_score\n",
    "        )\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc[\"content\"] for doc in results])\n",
    "            sources = [\n",
    "                {\n",
    "                    \"source\": doc[\"metadata\"].get(\"source\", \"unknown\"),\n",
    "                    \"page\": doc[\"metadata\"].get(\"page\", \"unknown\"),\n",
    "                    \"score\": doc[\"similarity_score\"],\n",
    "                    \"preview\": doc[\"content\"][:120] + \".....\",\n",
    "                }\n",
    "                for doc in results\n",
    "            ]\n",
    "\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\" \n",
    "            Use the following context to answer question concisely\n",
    "            context:{context}\n",
    "            question:{question}\n",
    "            answer:\n",
    "            \"\"\"\n",
    "\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        #Adding citation\n",
    "\n",
    "        citations = [f\"[{i+1}] {src['source']} page{src['page']}\" for i, src in enumerate(sources)]\n",
    "        answer_with_citation = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "\n",
    "        #Summarize the answer\n",
    "        summary = None\n",
    "\n",
    "        if summarize and answer:\n",
    "            summary_prompt= f\"Summarize the following answer in 2 snetences:\\n{answer}\"\n",
    "            summary_response = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_response.content\n",
    "\n",
    "        #Store query history\n",
    "\n",
    "        self.history.append({\n",
    "            'question':question,\n",
    "            'answer':answer,\n",
    "            'sources':sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citation,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "22d6a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Offences related to religion'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "\n",
      "Final Answer: *   295. Injuring or defiling place of worship, with intent to insult the religion of any class.\n",
      "*   295A. Deliberate and malicious acts, intended to outrage religious feelings of any class by insulting its religion or religious beliefs.\n",
      "*   296. Disturbing religious assembly.\n",
      "*   297. Trespassing on burial places, etc.\n",
      "*   298. Uttering words, etc., with deliberate intent to wound the religious feelings.\n",
      "\n",
      "Citations:\n",
      "[1] ../data/pdf/repealedfileopen.pdf page7\n",
      "[2] ../data/pdf/repealedfileopen.pdf page7\n",
      "[3] ../data/pdf/repealedfileopen.pdf page7\n",
      "Summary: These legal provisions criminalize deliberate acts intended to insult or outrage religious feelings and beliefs, encompassing actions like defiling places of worship or uttering offensive words. Additionally, they address disturbing religious assemblies and trespassing on sacred burial grounds.\n",
      "History: {'question': 'Offences related to religion', 'answer': '*   295. Injuring or defiling place of worship, with intent to insult the religion of any class.\\n*   295A. Deliberate and malicious acts, intended to outrage religious feelings of any class by insulting its religion or religious beliefs.\\n*   296. Disturbing religious assembly.\\n*   297. Trespassing on burial places, etc.\\n*   298. Uttering words, etc., with deliberate intent to wound the religious feelings.', 'sources': [{'source': '../data/pdf/repealedfileopen.pdf', 'page': 7, 'score': 0.4629754424095154, 'preview': '289. Negligent conduct with respect to animal.  \\n290. Punishment for public nuisance in cases not otherwi se provided fo.....'}, {'source': '../data/pdf/repealedfileopen.pdf', 'page': 7, 'score': 0.4629754424095154, 'preview': '289. Negligent conduct with respect to animal.  \\n290. Punishment for public nuisance in cases not otherwi se provided fo.....'}, {'source': '../data/pdf/repealedfileopen.pdf', 'page': 7, 'score': 0.4629754424095154, 'preview': '289. Negligent conduct with respect to animal.  \\n290. Punishment for public nuisance in cases not otherwi se provided fo.....'}], 'summary': 'These legal provisions criminalize deliberate acts intended to insult or outrage religious feelings and beliefs, encompassing actions like defiling places of worship or uttering offensive words. Additionally, they address disturbing religious assemblies and trespassing on sacred burial grounds.'}\n"
     ]
    }
   ],
   "source": [
    "adv_rag = AdvancedRAGPipeline(rag_retriever,llm)\n",
    "result = adv_rag.query(\n",
    "    \"Offences related to religion\",\n",
    "    top_k=3,\n",
    "    min_score=0.1,\n",
    "    \n",
    "    summarize=True\n",
    ")\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05735b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
